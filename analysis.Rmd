---
title: "Multimedia Meta-analysis Scripts"
date: "Updated: `r format(Sys.Date(), format='%B %d, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 5
    number_sections: no
---

<br/>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.retina = 4)
```

```{r}
# Libraries
pacman::p_load(metafor, readxl, MAd, metaforest, dmetar, DT, robumeta, janitor, tidyverse)

# Parameters
data_file <- here::here("data", "Multimedia Meta Data.xlsx")
```


```{r}
### Load all data

df_raw <-
  bind_rows(
    "DSN" = read_xlsx(data_file, sheet = "Decoding-DSN") %>% rename_at(vars(-c(1:2)), ~ str_replace(., "DSN", "")),
    "DRD" = read_xlsx(data_file, sheet = "Decoding-DRD") %>% rename_at(vars(-c(1:2)), ~ str_replace(., "DRD", "")),
    "DRP" = read_xlsx(data_file, sheet = "Decoding-DRP") %>% rename_at(vars(-c(1:2)), ~ str_replace(., "DRP", "")),
    "LSN" = read_xlsx(data_file, sheet = "Linguistic Comprehension-LSN") %>% rename_at(vars(-c(1:2)), ~ str_replace(., "LSN", "")),
    "LRD" = read_xlsx(data_file, sheet = "Linguistic Comprehension-LRD") %>% rename_at(vars(-c(1:2)), ~ str_replace(., "LRD", "")),
    "LRP" = read_xlsx(data_file, sheet = "Linguistic Comprehension-LRP") %>% rename_at(vars(-c(1:2)), ~ str_replace(., "LRP", "")),
    "CSN" = read_xlsx(data_file, sheet = "Reading Comprehension-CSN") %>% rename_at(vars(-c(1:2)), ~ str_replace(., "CSN", "")),
    "CRD" = read_xlsx(data_file, sheet = "Reading Comprehension-CRD") %>% rename_at(vars(-c(1:2)), ~ str_replace(., "CRD", "")),
    #"CRP" = read_xlsx(data_file, sheet = "Reading Comprehension-CRP") %>% rename_at(vars(-c(1:2)), ~ str_replace(., "CRP", "")),
    "WCSN" = read_xlsx(data_file, sheet = "Writing Conventions-WCSN") %>% rename_at(vars(-c(1:2)), ~ str_replace(., "WCSN", "")),
    "WCRD" = read_xlsx(data_file, sheet = "Writing Conventions-WCRD") %>% rename_at(vars(-c(1:2)), ~ str_replace(., "WCRD", "")),
    "WPSN" = read_xlsx(data_file, sheet = "Writing Proficiency-WPSN") %>% rename_at(vars(-c(1:2)), ~ str_replace(., "WPSN", "")),
    "WPRD" = read_xlsx(data_file, sheet = "Writing Proficiency-WPRD") %>% rename_at(vars(-c(1:2)), ~ str_replace(., "WPRD", "")),
    .id = "type"
  ) %>% 
  rename(study_id = `STUDYID`, AUTYR = `Author (Year)`) %>%
  drop_na(study_id) %>%
  remove_empty() %>%
  select(-AUTYR) %>% 
  select(study_id, type, sort(current_vars()))

# remove redundant rows
df_raw$na_count <- apply(df_raw, 1, function(x) sum(is.na(x)))
df_raw <- df_raw %>% filter(na_count < (ncol(df_raw) - 3))
```


```{r, eval=F}
df_direct_es <-
  read_xlsx(data_file, sheet = "Effect Size Only 1") %>% 
  bind_rows(read_xlsx(data_file, sheet = "Effect Size Only 2")) %>%
  bind_rows(read_xlsx(data_file, sheet = "Effect Size Only 3")) %>%
  bind_rows(read_xlsx(data_file, sheet = "Effect Size Only 4")) %>% 
  remove_empty() %>%
  transmute(study_id = STUDYID, type = "direct") %>% 
  distinct(study_id, type)

# df_raw <- df_raw %>% bind_rows(df_direct_es)
```



```{r, eval=FALSE}
# general checks
df_raw %>% glimpse()
df_raw %>% count(type)
df_raw %>% summarize_at(vars(1, 2, 243), ~ mean(is.na(.)))
df_raw %>% get_dupes(type, study_id)
```


### Study and measure overview

```{r}
# Add in correct author (year)
df_raw <-
  df_raw %>% 
  inner_join(
    read_xlsx(data_file, sheet = "All Studies") %>% 
      select(study_id = `STUDYID`, AUTYR = `Author (Year)`) %>% 
      drop_na(AUTYR),
    by = "study_id"
  ) %>% 
  relocate(type, study_id, AUTYR) %>% 
  arrange(type, study_id, AUTYR)

df_raw %>% 
  count(AUTYR, type) %>% 
  group_by(AUTYR) %>% 
  mutate(n = row_number()) %>%
  ungroup() %>% 
  pivot_wider(names_from = n, values_from = type, names_prefix = "Measure ") %>% 
  rename(`Author (Year)` = AUTYR) %>% 
  datatable()
```

---

<br/>

### Calculated effect sizes


```{r}
# creating needed control columns
# for (m in 1:2) {
#   for (n in 1:2) {
#     if ((str_glue("T{m}{n}MPost") %in% colnames(df_post)) & !(str_glue("C{m}{n}MPost") %in% colnames(df_post))) {
#       df_post[, str_c("C", m, n, "MPost")] = df_post[, str_c("C", m - 1, n, "MPost")]
#       df_post[, str_c("C", m, n, "NPost")] = df_post[, str_c("C", m - 1, n, "NPost")]
#       df_post[, str_c("C", m, n, "SPost")] = df_post[, str_c("C", m - 1, n, "SPost")]
#     }
#   }
# }
```



```{r}
### Post only

df_post <- df_raw

for (a in 1:9) {
  for (t in 1:9) {
    for (c in 1:9) {
      if (
        str_glue("T{t}{a}MPost") %in% colnames(df_post) & 
        str_glue("C{c}{a}MPost") %in% colnames(df_post)
      ) {
        df_post <-
          escalc(
            data = df_post,
            measure = "SMD",
            m1i = df_post[, str_c("T", t, a, "MPost")] %>% unlist(),
            m2i = df_post[, str_c("C", c, a, "MPost")] %>% unlist(),
            sd1i = df_post[, str_c("T", t, a, "SPost")] %>% unlist(),
            sd2i = df_post[, str_c("C", c, a, "SPost")] %>% unlist(),
            n1i = df_post[, str_c("T", t, a, "NPost")] %>% unlist(),
            n2i = df_post[, str_c("C", c, a, "NPost")] %>% unlist(),
            var.names = c(str_glue("ES{a}_{t}{c}"), str_glue("EV{a}_{t}{c}"))
          )
      }
    }
  }
}

df_post <-
  df_post %>% 
  select(study_id, AUTYR, type, starts_with("ES")) %>% 
  pivot_longer(cols = starts_with("ES"), names_to = "num", values_to = "ES", values_drop_na = T) %>%
  mutate(num = str_sub(num, 3)) %>% 
  left_join(
    df_post %>% 
      select(study_id, AUTYR, type, starts_with("EV")) %>% 
      pivot_longer(cols = starts_with("EV"), names_to = "num", values_to = "EV", values_drop_na = T) %>% mutate(num = str_sub(num, 3)),
    by = c("study_id", "AUTYR", "type", "num")
  )
```




```{r, eval=F}
# creating needed control columns
# for (m in 1:9) {
#   for (n in 1:9) {
#     if ((str_glue("T{m}{n}MPost") %in% colnames(df_prepost)) & !(str_glue("C{m}{n}MPost") %in% colnames(df_prepost))) {
#       df_prepost[, str_c("C", m, n, "MPost")] = df_prepost[, str_c("C", m - 1, n, "MPost")]
#       df_prepost[, str_c("C", m, n, "NPost")] = df_prepost[, str_c("C", m - 1, n, "NPost")]
#       df_prepost[, str_c("C", m, n, "SPost")] = df_prepost[, str_c("C", m - 1, n, "SPost")]
#     }
#     if ((str_glue("T{m}{n}MPre") %in% colnames(df_prepost)) & !(str_glue("C{m}{n}MPre") %in% colnames(df_prepost))) {
#       df_prepost[, str_c("C", m, n, "MPre")] = df_prepost[, str_c("C", m - 1, n, "MPre")]
#       df_prepost[, str_c("C", m, n, "NPre")] = df_prepost[, str_c("C", m - 1, n, "NPre")]
#       df_prepost[, str_c("C", m, n, "SPre")] = df_prepost[, str_c("C", m - 1, n, "SPre")]
#     }
#   }
# }
```


```{r}
# Pre and Post

df_prepost <- df_raw

# treatment (post-pre)
for (a in 1:9) {
  for (t in 1:9) {
    if (str_glue("T{t}{a}MPost") %in% colnames(df_prepost) & str_glue("T{t}{a}MPre") %in% colnames(df_prepost)) {
      df_prepost <-
        escalc(
          data = df_prepost,
          measure = "SMCR",
          m1i = df_prepost[, str_c("T", t, a, "MPost")] %>% unlist(),
          m2i = df_prepost[, str_c("T", t, a, "MPre")] %>% unlist(),
          sd1i = df_prepost[, str_c("T", t, a, "SPre")] %>% unlist(),
          ni = df_prepost[, str_c("T", t, a, "NPost")] %>% unlist(),
          ri = rep(0.5, 125),
          var.names = c(str_glue("TES{a}_{t}"), str_glue("TEV{a}_{t}"))
        )
    }
  }
}

# control (post-pre)
for (a in 1:9) {
  for (c in 1:9) {
    if (str_glue("C{c}{a}MPost") %in% colnames(df_prepost) & str_glue("C{c}{a}MPre") %in% colnames(df_prepost)) {
      df_prepost <-
        escalc(
          data = df_prepost,
          measure = "SMCR",
          m1i = df_prepost[, str_c("C", c, a, "MPost")] %>% unlist(),
          m2i = df_prepost[, str_c("C", c, a, "MPre")] %>% unlist(),
          sd1i = df_prepost[, str_c("C", c, a, "SPre")] %>% unlist(),
          ni = df_prepost[, str_c("C", c, a, "NPost")] %>% unlist(),
          ri = rep(0.5, 125),
          var.names = c(str_glue("CES{a}_{c}"), str_glue("CEV{a}_{c}"))
        )
    }
  }
}



# ES and EV taken together
for (a in 1:9) {
  for (t in 1:9) {
    for (c in 1:9) {
      if (
        !(str_glue("TES{a}_{t}") %in% colnames(df_prepost)) | 
        !(str_glue("TEV{a}_{t}") %in% colnames(df_prepost)) |
        !(str_glue("CES{a}_{c}") %in% colnames(df_prepost)) | 
        !(str_glue("CEV{a}_{c}") %in% colnames(df_prepost))
      ) {
        next
      }
      # subtracting effect size
      df_prepost[, str_c("ES", a, "_", t, c)] <- 
        (df_prepost[, str_c("TES", a, "_", t)] %>% unlist()) -
        (df_prepost[, str_c("CES", a, "_", c)] %>% unlist())
      # adding variance
      df_prepost[, str_c("EV", a, "_", t, c)] <- 
        (df_prepost[, str_c("TEV", a, "_", t)] %>% unlist()) +
        (df_prepost[, str_c("CEV", a, "_", c)] %>% unlist())
    }
  }
}

df_prepost <-
  df_prepost %>% 
  select(study_id, AUTYR, type, starts_with("ES")) %>% 
  pivot_longer(cols = starts_with("ES"), names_to = "num", values_to = "ES", values_drop_na = T) %>%
  mutate(num = str_sub(num, 3)) %>% 
  left_join(
    df_prepost %>%
      select(study_id, AUTYR, type, starts_with("EV")) %>% 
      pivot_longer(cols = starts_with("EV"), names_to = "num", values_to = "EV", values_drop_na = T) %>% 
      mutate(num = str_sub(num, 3)),
    by = c("study_id", "AUTYR", "type", "num")
  )
```


```{r}
df_es_calc <-
  full_join(df_prepost, df_post, by = c("study_id", "AUTYR", "type", "num")) %>% 
  mutate(
    ES.x = if_else(is.na(ES.x) & !is.na(ES.y), ES.y, ES.x),
    EV.x = if_else(is.na(EV.x) & !is.na(EV.y), EV.y, EV.x)
  ) %>% 
  select(study_id, AUTYR, type, ES = ES.x, EV = EV.x)
```


```{r}
#### Directly entered ES

df_es_direct <- tibble()
```


```{r, fig.retina=4}
#### Combining all

df_append <- 
  bind_rows(df_es_calc, df_es_direct) %>% 
  # left_join(
  #   read_xlsx(data_file, sheet = "StudyChar") %>% 
  #     drop_na(AUTYR) %>% 
  #     fill(Performance, Detection, Attrition, Reporting),
  #   by = "AUTYR"
  # ) %>%
  # mutate(
  #   LowIncome = recode(LowIncome, "0" = "0", "1" = "1", .default = NA_character_) %>% as.integer(),
  #   Hours = Hours %>% parse_number(),
  #   CONT = recode(CONT, "BAU" = "0", "ALT" = "1") %>% as.integer()
  # ) %>%
  arrange(type, study_id) %>%
  select(type, stdid = study_id, AUTYR, everything())

cor_es <-
  df_append %>%
  unite("type_stdid", c("type", "stdid")) %>% 
  agg(id = type_stdid, es = ES, var = EV, method = "BHHR", data = .) %>% 
  separate(id, c("type", "stdid")) %>% 
  rename(ES = es, EV = var)

df_clean <-
  df_append %>% 
  distinct(type, stdid, AUTYR) %>%
  mutate(stdid = as.character(stdid)) %>% 
  left_join(cor_es, by = c("type", "stdid")) %>% 
  mutate_if(is.character, ~ str_replace_all(., '[\n\t]', '')) %>% 
  arrange(type, stdid)


# df_clean <-
#   df_append %>%
#   group_by(type, stdid) %>%
#   summarize_at(vars(Content:Hours), ~ round(mean(.))) %>%
#   ungroup() %>%
#   left_join(cor_es, by = c("type", "stdid")) %>% 
#   select(type, stdid, ES, EV, everything()) %>% 
#   mutate(
#     design = case_when(
#       RCT == 1 ~ "RCT",
#       QED == 1 ~ "QED",
#       WSD == 1 ~ "WSD",
#       TRUE ~ NA_character_
#     ) %>% as_factor(),
#     grade = case_when(
#       (GradeK + Grade1 + Grade2) > 0 & (Grade3 + Grade4 + Grade5) == 0 ~ "K-2",
#       (Grade3 + Grade4 + Grade5) > 0 & (GradeK + Grade1 + Grade2) == 0 ~ "3-5",
#       TRUE ~ "Both"
#     ) %>% as_factor(),
#     grouping = case_when(
#       (WholeCl == 1) & (SmallGr == 0) & (Indiv == 0) ~ 1,
#       TRUE ~ 0
#     ),
#     CONT = CONT %>% factor(labels = c("BAU", "ALT")),
#     TCOM = if_else(TLC == 1 | TRC == 1, 1, 0)
#   ) %>%
#   select(-c(RCT, QED, WSD, WholeCl, SmallGr, Indiv), -starts_with("Grade", ignore.case = F)) %>% 
#   left_join(
#     read_xlsx(data_file, sheet = "citations"),
#     by = c("type", "stdid")
#   ) %>% 
#   mutate(
#     type = type %>% as_factor(),
#     citation = if_else(str_detect(type, "S$"), str_c(citation, " "), citation)
#   )

rm(df_es_calc, df_es_direct, df_post, df_prepost)
#df_clean %>% summary()
```


```{r}
df_clean %>% 
  relocate(AUTYR, stdid) %>%
  arrange(AUTYR, type) %>% 
  select(`Author (Year)` = AUTYR, type, ES, EV) %>% 
  mutate_if(is.numeric, ~ round(., 4)) %>% 
  datatable()
```


```{r}
#### Summary stats

# df_clean %>% count(type)
# df_clean %>% arrange(type, ES) %>% writexl::write_xlsx("df_clean.xlsx")
# df_clean %>% select(stdid, type) %>% arrange(stdid, type) %>% writexl::write_xlsx("temp.xlsx")
# df_clean %>% count(type, stdid)

df_c <- df_clean %>% filter(type %in% c("CRD", "CSN"))
df_d <- df_clean %>% filter(type %in% c("DRD", "DRP", "DSN"))
df_l <- df_clean %>% filter(type %in% c("LRD", "LRP", "LSN"))
df_w <- df_clean %>% filter(type %in% c("WCRD", "WCSN", "WPRD", "WPSN"))

# changes for rebecca
# df_v %>% filter(stdid %in% c("Coyne10", "Coyne19", "Puhal", "Pullen"), type == "VR") %>% rma(
#     yi = ES, 
#     vi = EV, 
#     data = ., 
#     method = "REML",
#     slab = citation
#   )
```


---

<br/>

### Synthesizing effect sizes


#### Decoding

Forest plot:

```{r, fig.retina = 4, fig.asp=1.8}
df_d %>%
  rma(
    yi = ES, 
    vi = EV, 
    data = ., 
    method = "REML",
    slab = AUTYR
  ) %>% 
  forest(
    order = "obs",
    xlab = "Decoding",
    addcred = T, 
    header = T,
    pch = 21,
    bg = "grey",
    lwd = 1.5
  )
```


DRD:

```{r}
df_d %>%
  filter(type == "DRD") %>% 
  rma(
    yi = ES, 
    vi = EV, 
    data = ., 
    method = "REML",
    slab = stdid
  )
```

DRP:

```{r}
df_d %>%
  filter(type == "DRP") %>% 
  rma(
    yi = ES, 
    vi = EV, 
    data = ., 
    method = "REML",
    slab = stdid
  )
```

DSN:

```{r}
df_d %>%
  filter(type == "DSN") %>% 
  rma(
    yi = ES, 
    vi = EV, 
    data = ., 
    method = "REML",
    slab = stdid
  )
```


---

<br/>

#### Reading Comprehension

Forest plot:

```{r, fig.retina = 4, fig.asp=1.5}
df_c %>%
  rma(
    yi = ES, 
    vi = EV, 
    data = ., 
    method = "REML",
    slab = AUTYR
  ) %>% 
  forest(
    order = "obs",
    xlab = "Reading Comprehension",
    addcred = T, 
    header = T,
    pch = 21,
    bg = "grey",
    lwd = 1.5
  )
```


CRD:

```{r}
df_c %>%
  filter(type == "CRD") %>% 
  rma(
    yi = ES, 
    vi = EV, 
    data = ., 
    method = "REML",
    slab = stdid
  )
```

CSN:

```{r}
df_c %>%
  filter(type == "CSN") %>% 
  rma(
    yi = ES, 
    vi = EV, 
    data = ., 
    method = "REML",
    slab = stdid
  )
```


---

<br/>


#### Language Comprehension

Forest plot:

```{r, fig.retina = 4, fig.asp=1.2}
df_l %>%
  rma(
    yi = ES, 
    vi = EV, 
    data = ., 
    method = "REML",
    slab = AUTYR
  ) %>% 
  forest(
    order = "obs",
    xlab = "Language Comprehension",
    addcred = T, 
    header = T,
    pch = 21,
    bg = "grey",
    lwd = 1.5
  )
```



LRD:

```{r}
df_l %>%
  filter(type == "LRD") %>% 
  rma(
    yi = ES, 
    vi = EV, 
    data = ., 
    method = "REML",
    slab = stdid
  )
```

LRP:

```{r}
df_l %>%
  filter(type == "LRP") %>% 
  rma(
    yi = ES, 
    vi = EV, 
    data = ., 
    method = "REML",
    slab = stdid
  )
```

LSN:

```{r}
df_l %>%
  filter(type == "LSN") %>% 
  rma(
    yi = ES, 
    vi = EV, 
    data = ., 
    method = "REML",
    slab = stdid
  )
```


---

<br/>

#### Writing

Forest plot:

```{r, fig.retina = 4, fig.asp=1.2}
df_w %>%
  rma(
    yi = ES, 
    vi = EV, 
    data = ., 
    method = "REML",
    slab = AUTYR
  ) %>% 
  forest(
    order = "obs",
    xlab = "Writing",
    addcred = T, 
    header = T,
    pch = 21,
    bg = "grey",
    lwd = 1.5
  )
```



WCSN:

```{r}
df_w %>%
  filter(type == "WCSN") %>% 
  rma(
    yi = ES, 
    vi = EV, 
    data = ., 
    method = "REML",
    slab = stdid
  )
```


WCRD:

```{r}
df_w %>%
  filter(type == "WCRD") %>% 
  rma(
    yi = ES, 
    vi = EV, 
    data = ., 
    method = "REML",
    slab = stdid
  )
```


WPSN:

```{r}
df_w %>%
  filter(type == "WPSN") %>% 
  rma(
    yi = ES, 
    vi = EV, 
    data = ., 
    method = "REML",
    slab = stdid
  )
```


WPRD:

```{r}
df_w %>%
  filter(type == "WPRD") %>% 
  rma(
    yi = ES, 
    vi = EV, 
    data = ., 
    method = "REML",
    slab = stdid
  )
```


